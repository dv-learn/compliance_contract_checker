{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22386e25-23ee-4e83-8287-ca60690bc888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f63ea67a-8246-418d-b711-f766fc1ba70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports for langchain\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings,ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "#from langchain.vectorstores import FAISS\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import Document\n",
    "from langchain.document_loaders import PyMuPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d90f123-615f-4f88-8b15-da10cf681662",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"gpt-4o-mini\"\n",
    "db_name=\"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64f484a0-9dc8-4f29-ae9f-dffe0600b963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env variables to .env file\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\",\"your-key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfeb2b0e-5b82-4f74-a200-8110332d08b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/contract_dataset/contracts/Schedule A ‚Äì Service Credits.pdf\n",
      "../data/contract_dataset/contracts/zoom_msa.pdf\n",
      "../data/contract_dataset/policies/procurement_policy.txt\n"
     ]
    }
   ],
   "source": [
    "folders = glob.glob(\"../data/contract_dataset/*\")\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    for file_path in glob.glob(f\"{folder}/**/*.*\", recursive=True):\n",
    "        print(file_path)\n",
    "        ext = os.path.splitext(file_path)[-1].lower()\n",
    "        try:\n",
    "            if ext in [\".txt\", \".md\", \".csv\"]:\n",
    "                loader = TextLoader(file_path)\n",
    "            elif ext == \".pdf\":\n",
    "                loader = PyMuPDFLoader(file_path)  # Use PDF-compatible loader\n",
    "            elif ext == \".json\":\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    content = f.read()\n",
    "                documents.append(Document(page_content=content, metadata={\"source\": file_path, \"doc_type\": doc_type}))\n",
    "    \n",
    "            else:\n",
    "                print(f\"Skipping unsupported file: {file_path}\")\n",
    "                continue\n",
    "            folder_docs = loader.load()\n",
    "            for doc in folder_docs:\n",
    "                doc.metadata[\"doc_type\"] = doc_type\n",
    "                documents.append(doc)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a43c6a8-36a7-4265-98c5-508be490b4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a92cf9e3-d73b-42b6-8312-c881d03f051e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '../data/contract_dataset/contracts/Schedule A ‚Äì Service Credits.pdf', 'file_path': '../data/contract_dataset/contracts/Schedule A ‚Äì Service Credits.pdf', 'page': 0, 'total_pages': 1, 'format': 'PDF 1.4', 'title': 'Schedule A ‚Äì Service Credits', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m138 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': '', 'doc_type': 'contracts'}, page_content='Zoom guarantees a monthly uptime of 99.9%. In the event of SLA breaches, the following \\nservice credits will apply: \\n \\n- Uptime 99.5% to 99.9%: 5% monthly service credit   \\n- Uptime 99.0% to 99.5%: 10% monthly service credit   \\n- Uptime below 99.0%: 20% monthly service credit   \\n \\nCredits are calculated based on the monthly invoice value. \\n \\nClaim Process: \\n- Customer must submit a claim within 30 days of the reported SLA breach. \\n- Zoom will validate the claim and apply the service credit to the following billing cycle. \\n \\n \\n')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db1a1f0-5814-4c63-9cdf-d0b3bb7d453f",
   "metadata": {},
   "source": [
    "### I am not chunking, as document looks small one.. lets see if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cca01c5d-6d2f-43c8-9a38-4b67bc468b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document types:policies, contracts\n"
     ]
    }
   ],
   "source": [
    "doc_types = set(doc.metadata[\"doc_type\"] for doc in documents)\n",
    "print(f\"Document types:{', '.join(doc_types)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b10c7fd-d0be-413b-8229-a7797e6e05c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put the chunks of data in to vector store that associates vector embeddings with each cunk\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6494f8e6-c025-4f81-b967-b1b917592687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Chroma data store already exists - if exist then delete the collection to start from scratch\n",
    "if(os.path.exists(db_name)):\n",
    "    Chroma(persist_directory=db_name,embedding_function=embeddings).delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2b1c484-d8ce-47f1-811f-2b6845fc09d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with: 3 documents.\n"
     ]
    }
   ],
   "source": [
    "vectorstore = Chroma.from_documents(documents=documents,embedding=embeddings,persist_directory=db_name)\n",
    "print(f\"Vectorstore created with: {vectorstore._collection.count()} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b064a4f-2bce-4b65-8a51-1a5902aa0ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00985571 -0.03031264  0.01611385 ... -0.00599824  0.01104578\n",
      " -0.0127625 ]\n",
      "The vector have 1,536 dimentions.\n"
     ]
    }
   ],
   "source": [
    " #Get one vector and find how many dimentions in to it\n",
    "collection = vectorstore._collection\n",
    "sample_embedding = collection.get(limit=1,include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "print(sample_embedding)\n",
    "dimentions = len(sample_embedding)\n",
    "print(f\"The vector have {dimentions:,} dimentions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f5f7bcc-b56a-4545-b902-4680425ddc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mb/lpy1xsnj19g5x_29hbtbqw_h0000gn/T/ipykernel_11175/3342613448.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key='chat_history',return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "# Create a new chat with OpenAI\n",
    "llm = ChatOpenAI(temperature=0.7, model=model)\n",
    "\n",
    "# Set up conversation memory\n",
    "memory = ConversationBufferMemory(memory_key='chat_history',return_messages=True)\n",
    "\n",
    "# The retriever is the abstraction over vectorstore that will be used in RAG\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Putting it all together: set up conversation chanin with gpt 3.5 LLM, memory and vector store\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm,retriever=retriever,memory=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f92c759-153b-4f63-b353-1587a6a023ae",
   "metadata": {},
   "source": [
    "\n",
    "###üîç Contract Understanding Questions\n",
    "üîç Contract Understanding Questions\n",
    "üìÑ Zoom MSA\n",
    "What is the effective date of the Zoom agreement?\n",
    "\n",
    "Does the Zoom contract auto-renew? If so, what are the terms?\n",
    "\n",
    "What notice period is required to terminate the Zoom agreement?\n",
    "\n",
    "What is the SLA uptime commitment mentioned in the Zoom MSA?\n",
    "\n",
    "What happens if Zoom breaches the SLA?\n",
    "\n",
    "How long does a customer have to claim service credits?\n",
    "\n",
    "Does the Zoom MSA mention GDPR compliance?\n",
    "\n",
    "Is there any reference to a document not included in the contract?\n",
    "\n",
    "üìÑ Schedule A\n",
    "What level of service credit is available if Zoom‚Äôs uptime falls to 99.2%?\n",
    "\n",
    "What must a customer do to claim a service credit?\n",
    "\n",
    "üìú Procurement Policy Alignment\n",
    "Does the Zoom contract meet the procurement policy requirement for termination notice?\n",
    "\n",
    "Does the Zoom MSA comply with the GDPR clause requirement from the procurement policy?\n",
    "\n",
    "Is the Zoom contract aligned with SLA breach penalty expectations in the procurement policy?\n",
    "\n",
    "Does the policy specify a timeline for contract review before renewal?\n",
    "\n",
    "Does the procurement policy prohibit auto-renewals longer than 12 months?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e463c71-6523-41ea-bdfd-ea3fb5aad500",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradio Magic\n",
    "def chat(message, history):\n",
    "    result = conversation_chain.invoke({\"question\": message})\n",
    "    return result[\"answer\"]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36c65678-e5ac-4e37-847a-9b3cbf811bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dvasani/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/components/chatbot.py:255: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view = gr.ChatInterface(chat).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2be92a0-5f2f-456d-9096-07abeb3d0646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2d6b2b-0fa5-4b68-acd7-adc1abfb6b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c53ad61-df21-425e-a872-a826f068193b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea42c82-f9cd-4af5-993e-0b7798719ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da36970-1c74-4054-867d-76914487d29b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
